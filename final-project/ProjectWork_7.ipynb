{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data shape: (11338, 3)\n",
      "Additional data shape: (2490, 3)\n",
      "Total data shape: (13826, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Weapons of Mass Destruction Found in Iraq Yet.</td>\n",
       "      <td>Weapons of Mass Destruction Found in Iraq.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A place of sorrow, after Pope John Paul II die...</td>\n",
       "      <td>Pope Benedict XVI is the new leader of the Rom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Herceptin was already approved to treat the si...</td>\n",
       "      <td>Herceptin can be used to treat breast cancer.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Judie Vivian, chief executive at ProMedica, a ...</td>\n",
       "      <td>The previous name of Ho Chi Minh City was Saigon.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is due in court later charged with the m...</td>\n",
       "      <td>Paul Stewart Hutchinson is accused of having s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  No Weapons of Mass Destruction Found in Iraq Yet.   \n",
       "1  A place of sorrow, after Pope John Paul II die...   \n",
       "2  Herceptin was already approved to treat the si...   \n",
       "3  Judie Vivian, chief executive at ProMedica, a ...   \n",
       "4  A man is due in court later charged with the m...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0         Weapons of Mass Destruction Found in Iraq.      2  \n",
       "1  Pope Benedict XVI is the new leader of the Rom...      0  \n",
       "2      Herceptin can be used to treat breast cancer.      0  \n",
       "3  The previous name of Ho Chi Minh City was Saigon.      0  \n",
       "4  Paul Stewart Hutchinson is accused of having s...      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9430</th>\n",
       "      <td>Inglish unterscheidet sich von Englisch durch ...</td>\n",
       "      <td>Inglisch ist das Gleiche wie Englisch.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>His ruthless campaigns resulted in more than 6...</td>\n",
       "      <td>500,000 Irish died and 100,000 were deported d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Televizyon'da bir şeyler izliyoruz.</td>\n",
       "      <td>Televizyondaki haberleri izliyorduk.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>You're all right now.</td>\n",
       "      <td>The struggle and pain is over.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Asıl önemli olan, aslında, dünyadaki pek çok M...</td>\n",
       "      <td>Dünyada bir sürü Milosevic var.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "9430  Inglish unterscheidet sich von Englisch durch ...   \n",
       "8649  His ruthless campaigns resulted in more than 6...   \n",
       "758                 Televizyon'da bir şeyler izliyoruz.   \n",
       "3424                              You're all right now.   \n",
       "829   Asıl önemli olan, aslında, dünyadaki pek çok M...   \n",
       "\n",
       "                                             hypothesis  label  \n",
       "9430             Inglisch ist das Gleiche wie Englisch.      2  \n",
       "8649  500,000 Irish died and 100,000 were deported d...      1  \n",
       "758                Televizyondaki haberleri izliyorduk.      1  \n",
       "3424                    The struggle and pain is over.       1  \n",
       "829                     Dünyada bir sürü Milosevic var.      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "raw_data      = pd.read_csv('../data/sentence-relations/train.csv', index_col='id')\n",
    "raw_submissions = pd.read_csv('../data/sentence-relations/test.csv', index_col='id')\n",
    "\n",
    "# Drop chinese and thai\n",
    "raw_data = raw_data[raw_data['lang_abv'] != 'zh']\n",
    "raw_data = raw_data[raw_data['lang_abv'] != 'th']\n",
    "\n",
    "raw_data = raw_data.drop(columns=['lang_abv', 'language'])\n",
    "raw_data.index = range(len(raw_data))\n",
    "\n",
    "additional_data = pd.read_csv('./glue_data/RTE/train.tsv', sep='\\t')\n",
    "additional_data = additional_data.drop(columns=['index'])\n",
    "additional_data.columns = ['premise', 'hypothesis', 'label']\n",
    "additional_data['label'] = additional_data['label'].apply(lambda x: 0 if x == 'entailment' else 2)\n",
    "\n",
    "print(f\"Raw data shape: {raw_data.shape}\")\n",
    "print(f\"Additional data shape: {additional_data.shape}\")\n",
    "\n",
    "# Merge the two datasets\n",
    "raw_data = pd.concat([raw_data, additional_data], ignore_index=True)\n",
    "raw_data = raw_data.drop_duplicates()\n",
    "raw_data = raw_data.reset_index(drop=True)\n",
    "\n",
    "print(f\"Total data shape: {raw_data.shape}\")\n",
    "\n",
    "training_data, test_data = train_test_split(raw_data, test_size=0.2, random_state=42)\n",
    "\n",
    "display(additional_data.head())\n",
    "display(training_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot label distribution\n",
    "training_data['label'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alex/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", truncation=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BertSentenceDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.X = self.data['premise'] + '[SEP]' + self.data['hypothesis']\n",
    "        self.y = self.data['label']\n",
    "\n",
    "        self.encoded = self.tokenizer(self.X.tolist(), padding=True, truncation=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encoded['input_ids'][idx],\n",
    "            'attention_mask': self.encoded['attention_mask'][idx],\n",
    "            'label': self.y.iloc[idx]\n",
    "        }\n",
    "\n",
    "bert_train_dataset = BertSentenceDataset(training_data, roberta_tokenizer)\n",
    "bert_test_dataset = BertSentenceDataset(test_data, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "id2label = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "label2id = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "num_labels = len(id2label)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=num_labels, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"roberta-base-sentence-relation\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running on device: {training_args.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/27650 [00:12<3:31:25,  2.18it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:158\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: BatchEncoding.to() got an unexpected keyword argument 'non_blocking'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/transformers/trainer.py:2165\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2162\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2164\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2166\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m~/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/accelerate/data_loader.py:461\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n",
      "File \u001b[0;32m~/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:160\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# `torch.Tensor.to(<int num>)` is not supported by `torch_npu` (see this [issue](https://github.com/Ascend/pytorch/issues/16)).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# This call is inside the try-block since is_npu_available is not supported by torch.compile.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_npu_available():\n",
      "File \u001b[0;32m~/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:800\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 800\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    802\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Studium/2-Master/ki-lab-ss23/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:800\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 800\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    802\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=bert_train_dataset,\n",
    "    eval_dataset=bert_test_dataset,\n",
    "    tokenizer=roberta_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:08<00:00, 10.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6948167085647583,\n",
       " 'eval_accuracy': 0.7991266375545851,\n",
       " 'eval_f1': 0.7975053326129699,\n",
       " 'eval_precision': 0.7997977316986625,\n",
       " 'eval_recall': 0.7971155023486721,\n",
       " 'eval_runtime': 8.2844,\n",
       " 'eval_samples_per_second': 165.854,\n",
       " 'eval_steps_per_second': 10.381}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('roberta-base-sentence-relation/checkpoint-4816', num_labels=num_labels, id2label=id2label, label2id=label2id)\n",
    "\n",
    "# Evaluate the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=bert_train_dataset,\n",
    "    eval_dataset=bert_test_dataset,\n",
    "    tokenizer=None,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
